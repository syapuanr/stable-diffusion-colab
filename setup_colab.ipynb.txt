{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üé® Stable Diffusion WebUI for Google Colab\n",
        "## Professional AI Image Generation Interface\n",
        "\n",
        "### Features:\n",
        "- ‚úÖ SD 1.5, SD 2.1, SDXL Support\n",
        "- ‚úÖ LoRA & Custom VAE\n",
        "- ‚úÖ Txt2Img & Img2Img\n",
        "- ‚úÖ Memory Optimized\n",
        "- ‚úÖ Public URL via Ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# 1. Check GPU\n",
        "!nvidia-smi\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"If you see GPU info above, you're good to go!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# 2. Clone Repository\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/USERNAME/your-sd-webui.git\"  # Ganti dengan repo Anda\n",
        "REPO_NAME = \"your-sd-webui\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    !git clone {REPO_URL}\n",
        "    print(\"‚úì Repository cloned\")\n",
        "else:\n",
        "    print(\"‚úì Repository already exists\")\n",
        "\n",
        "%cd {REPO_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# 3. Install Dependencies\n",
        "print(\"Installing dependencies... This may take a few minutes.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úì All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_ngrok"
      },
      "outputs": [],
      "source": [
        "# 4. Setup Ngrok Tunnel (OPTIONAL)\n",
        "# Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "NGROK_TOKEN = \"\"  # Paste your token here\n",
        "\n",
        "if NGROK_TOKEN:\n",
        "    !ngrok config add-authtoken {NGROK_TOKEN}\n",
        "    print(\"‚úì Ngrok configured\")\n",
        "else:\n",
        "    print(\"‚ö† No Ngrok token provided. You can still access via Gradio share link.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_webui"
      },
      "outputs": [],
      "source": [
        "# 5. Launch WebUI\n",
        "print(\"üöÄ Starting Stable Diffusion WebUI...\")\n",
        "print(\"=\"*60)\n",
        "print(\"Wait for the interface to load.\")\n",
        "print(\"You'll see a URL to access the WebUI.\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Launch with share enabled (creates public Gradio link)\n",
        "!python main.py --share --server-name 0.0.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guide"
      },
      "source": [
        "## üìù Quick Start Guide\n",
        "\n",
        "### First Time Setup:\n",
        "1. **Load a Model:**\n",
        "   - Go to \"Model Settings\" accordion\n",
        "   - Choose \"HuggingFace\" and select a model\n",
        "   - Click \"Load Model\" and wait\n",
        "\n",
        "2. **Generate Your First Image:**\n",
        "   - Go to \"Text-to-Image\" tab\n",
        "   - Enter your prompt\n",
        "   - Click \"Generate\"\n",
        "\n",
        "### Recommended Starting Models:\n",
        "- **SD 1.5:** `runwayml/stable-diffusion-v1-5` (Fast, 512x512)\n",
        "- **SD 2.1:** `stabilityai/stable-diffusion-2-1` (Good quality, 768x768)\n",
        "- **SDXL:** `stabilityai/stable-diffusion-xl-base-1.0` (Best quality, 1024x1024, needs more VRAM)\n",
        "\n",
        "### Tips for Colab:\n",
        "- Start with SD 1.5 if you have T4 GPU (15GB VRAM)\n",
        "- Use SDXL only with A100 or V100 GPUs\n",
        "- Enable CPU Offload in Advanced Settings if you get OOM errors\n",
        "- Keep batch size at 1 for large models\n",
        "\n",
        "### Troubleshooting:\n",
        "- **Out of Memory:** Enable CPU Offload in Advanced Settings\n",
        "- **Slow Generation:** This is normal on T4 GPUs, be patient\n",
        "- **Model Loading Fails:** Check your internet connection\n",
        "\n",
        "### Uploading Custom Models:\n",
        "1. Upload your .safetensors file to Colab\n",
        "2. Move it to `models/checkpoints/` folder\n",
        "3. Select \"Local File\" in Model Settings\n",
        "4. Choose your file and click Load\n",
        "\n",
        "---\n",
        "\n",
        "**Need Help?** Check the GitHub repository for documentation and examples."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}