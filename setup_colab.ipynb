{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f29b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üé® Stable Diffusion WebUI for Google Colab\\n\",\n",
    "    \"## Professional AI Image Generation Interface\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Features:\\n\",\n",
    "    \"- ‚úÖ SD 1.5, SD 2.1, SDXL Support\\n\",\n",
    "    \"- ‚úÖ LoRA & Custom VAE\\n\",\n",
    "    \"- ‚úÖ Txt2Img & Img2Img\\n\",\n",
    "    \"- ‚úÖ Memory Optimized\\n\",\n",
    "    \"- ‚úÖ Public URL via Ngrok\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 1. Check GPU\\n\",\n",
    "    \"!nvidia-smi\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"If you see GPU info above, you're good to go!\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 2. Clone Repository\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"REPO_URL = \\\"https://github.com/USERNAME/your-sd-webui.git\\\"  # Ganti dengan repo Anda\\n\",\n",
    "    \"REPO_NAME = \\\"your-sd-webui\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not os.path.exists(REPO_NAME):\\n\",\n",
    "    \"    !git clone {REPO_URL}\\n\",\n",
    "    \"    print(\\\"‚úì Repository cloned\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚úì Repository already exists\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"%cd {REPO_NAME}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 3. Install Dependencies\\n\",\n",
    "    \"print(\\\"Installing dependencies... This may take a few minutes.\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"!pip install -q -r requirements.txt\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"‚úì All dependencies installed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 4. Setup Ngrok Tunnel (OPTIONAL)\\n\",\n",
    "    \"# Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\\n\",\n",
    "    \"\\n\",\n",
    "    \"NGROK_TOKEN = \\\"\\\"  # Paste your token here\\n\",\n",
    "    \"\\n\",\n",
    "    \"if NGROK_TOKEN:\\n\",\n",
    "    \"    !ngrok config add-authtoken {NGROK_TOKEN}\\n\",\n",
    "    \"    print(\\\"‚úì Ngrok configured\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ö† No Ngrok token provided. You can still access via Gradio share link.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 5. Launch WebUI\\n\",\n",
    "    \"print(\\\"üöÄ Starting Stable Diffusion WebUI...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"Wait for the interface to load.\\\")\\n\",\n",
    "    \"print(\\\"You'll see a URL to access the WebUI.\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60 + \\\"\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Launch with share enabled (creates public Gradio link)\\n\",\n",
    "    \"!python main.py --share --server-name 0.0.0.0\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìù Quick Start Guide\\n\",\n",
    "    \"\\n\",\n",
    "    \"### First Time Setup:\\n\",\n",
    "    \"1. **Load a Model:**\\n\",\n",
    "    \"   - Go to \\\"Model Settings\\\" accordion\\n\",\n",
    "    \"   - Choose \\\"HuggingFace\\\" and select a model\\n\",\n",
    "    \"   - Click \\\"Load Model\\\" and wait\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Generate Your First Image:**\\n\",\n",
    "    \"   - Go to \\\"Text-to-Image\\\" tab\\n\",\n",
    "    \"   - Enter your prompt\\n\",\n",
    "    \"   - Click \\\"Generate\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Recommended Starting Models:\\n\",\n",
    "    \"- **SD 1.5:** `runwayml/stable-diffusion-v1-5` (Fast, 512x512)\\n\",\n",
    "    \"- **SD 2.1:** `stabilityai/stable-diffusion-2-1` (Good quality, 768x768)\\n\",\n",
    "    \"- **SDXL:** `stabilityai/stable-diffusion-xl-base-1.0` (Best quality, 1024x1024, needs more VRAM)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Tips for Colab:\\n\",\n",
    "    \"- Start with SD 1.5 if you have T4 GPU (15GB VRAM)\\n\",\n",
    "    \"- Use SDXL only with A100 or V100 GPUs\\n\",\n",
    "    \"- Enable CPU Offload in Advanced Settings if you get OOM errors\\n\",\n",
    "    \"- Keep batch size at 1 for large models\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Troubleshooting:\\n\",\n",
    "    \"- **Out of Memory:** Enable CPU Offload in Advanced Settings\\n\",\n",
    "    \"- **Slow Generation:** This is normal on T4 GPUs, be patient\\n\",\n",
    "    \"- **Model Loading Fails:** Check your internet connection\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Uploading Custom Models:\\n\",\n",
    "    \"1. Upload your .safetensors file to Colab\\n\",\n",
    "    \"2. Move it to `models/checkpoints/` folder\\n\",\n",
    "    \"3. Select \\\"Local File\\\" in Model Settings\\n\",\n",
    "    \"4. Choose your file and click Load\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Need Help?** Check the GitHub repository for documentation and examples.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"accelerator\": \"GPU\",\n",
    "  \"colab\": {\n",
    "   \"gpuType\": \"T4\",\n",
    "   \"provenance\": []\n",
    "  },\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
